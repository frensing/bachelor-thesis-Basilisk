\subsection{\acl{tbs}}
The implementation of the \acl{tbs} was lacking big parts of its functionality.
To explain the implementation steps, we follow the benchmarking process that is used when a new benchmark job is send to the \ac{tbs}.
\\

The \ac{jms} sends the created benchmark jobs via the message queues of RabbitMQ.
The \ac{tbs} stores these jobs internally in a job queue.
Benchmark jobs can be manually aborted by the user over the REST API of the \ac{jms}.
When a benchmark job is aborted, the \ac{jms} will send a message to the \ac{tbs}.
If the job has not been processed yet, the \ac{tbs} will skip the job when looking for the next job to run.
\\

When a benchmark job is started, the \ac{tbs} needs to create a Docker image first, that contains the \ts{} that will be benchmarked.
Afterwards, a container is build and configured from the image.
The configuration is stored in the data model of the \ac{jms} and is provided with the benchmark job to the \ac{tbs}.
Then, the \iguana{} configuration file is created and the framework gets started.
After \iguana{} performed the benchmark on the Container, \iguana{} writes the results to the \ac{jsts} and the \ac{tbs} stops and removes the Docker container.

The implementation of this process is explained in the following sections.


\subsubsection{Creation of Docker Images}
The setup and creation of the Docker images containing the \ts{} for a benchmarking job can be divided into two branches.
Triplestores from \dockh{} repositories are easier to setup than \tsp{} stored in \gh{} repositories.

For a benchmark of a \ts{} that is configured as a \dockh{} repository, the only task is to pull the Docker image from \dockh{} by providing the repository name and owner and the image tag that marks the new release.

The creation of a Docker image from a \gh{} repository is more complicated than simply downloading an image from \dockh{}.
First the source code of the repository has to be downloaded. 
Then the Dockerfile needs to be located and a build needs to be initiated, which often requires additional parameters and configurations.
Because of this increased complexity, we focused on the benchmark process of \dockh{} repositories.
As explained in the time schedule (\ref{sec:time_schedule}) the first priority was to implement a fully running process, which was easier to accomplish for a \dockh{} repository.
\\

After the creation of the Docker image, the benchmark process is the same for both repository types.


\subsubsection{Creating and Starting a Docker Container}
After the Docker image is available, a Docker container is configured and started.

The \ts{} which is the target of the benchmark job will be run in the Docker container.
For a successful benchmark the \ts{} needs to be accessible from the \ac{tbs} and also needs access to the dataset to calculate the results for the benchmark queries.

To be accessible from outside the container, the container is configured to expose and listen to specific ports on the network.
Through these ports the SPARQL endpoint will be accessible, which \iguana{} uses to send queries and receive the results.

To give the \ts{} access to the dataset of the benchmark, the dataset can be provided in two different ways.
Either it is available inside the Docker container through a published volume provided by the server.
In this case the \ts{} can use the file directly from the file system.
The second option is to provide the dataset by uploading it through the SPARQL endpoint of the running \ts{}.
For this option a shell script needs to be provided by the \ts{} configuration.
This script is executed by the \iguana{} framework before the benchmark is started.

After these configurations, the container gets started and the actual benchmark can run.


\subsubsection{Configuration and Start of the IGUANA Framework}
The actual benchmark is performed by the \iguana{} framework (\ref{sec:iguana}).
The framework takes a YAML or JSON file containing the benchmark configuration as the start parameter.
Therefore the \ac{tbs} creates this configuration file from the provided information of the current benchmark job.
This contains the name of the dataset, the address of the SPARQL endpoint and the configuration of the benchmark to be performed.
The benchmark configuration contains the location of the query file and possible time limits or thread counts for the \iguana{}-workers.
Lastly the connection for the \ac{jsts} is provided.
This connection is used after the benchmark to write the benchmark results to the storage.
The \iguana{} configuration gets encoded in JSON and is written to a temporary file on the server.
\\

The next step is to start the benchmark by starting the \iguana{} framework with the created benchmark configuration.
The \iguana{} framework is located on the server as an executable jar file.
It gets started as an individual process on the server with the configuration file as the argument.
If the dataset needs to be loaded after the \ts{} is started, \iguana{} executes the provided loading script first, before starting the actual benchmark.


\subsubsection{REST endpoint to Control Job Starting}
To have a better control of the execution of the benchmark jobs, the \ac{tbs} is extended with REST endpoint that can start or stop the execution service.
This functionality works similarly to the \ac{hcs}.
When the service is started over the endpoint, the queue of benchmark jobs is read and the next job in the queue is started.
When the user decides to stop the benchmark execution service, the running job will be finished, but no new job will be started form the job queue.


\subsubsection{Benchmark Cleanup}
When the \iguana{} framework has finished the benchmark some cleanup is happening to free server resources.
This includes removing the \iguana{} configuration file, the Docker container and the Docker image.
The Docker container gets stopped and removed by the \ac{tbs}.
After that the Docker image is also removed to free up disk space.
